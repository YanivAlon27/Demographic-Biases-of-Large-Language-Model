{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c660edb",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Imports & Setup](#imports--setup)\n",
    "- [Data Loading](#data-loading)\n",
    "- [Preprocessing & Feature Engineering](#preprocessing--feature-engineering)\n",
    "- [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f114f24f",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee764f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa536d9",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r\"path\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d42941",
   "metadata": {},
   "source": [
    "# Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapping_dict = {\n",
    "    'ct': 'ct',\n",
    "    None: 'unknown',\n",
    "    'ct angiography': 'angiography',\n",
    "    'ct arthrography': 'ct',\n",
    "    'ct function and morphology': 'ct',\n",
    "    'ct maxillofacial': 'ct',\n",
    "    'ct maxface': 'ct',\n",
    "    'ct venography': 'ct',\n",
    "    'ct angiography-perfusion': 'angiography',\n",
    "    'ct colonography': 'ct',\n",
    "    'ct enterography': 'ct',\n",
    "    'lumbar nerve root block': 'nerve injection',\n",
    "    'xray': 'xray',\n",
    "    'ct high resolution': 'ct',\n",
    "    'ct quantitative': 'ct',\n",
    "    'ct urography': 'ct',\n",
    "    'mri': 'mri',\n",
    "    'ultrasound': 'ultrasound',\n",
    "    'follow up ': 'follow-up',\n",
    "    'intestine': 'gi imaging',\n",
    "    'epidural steroid injection': 'nerve injection',\n",
    "    'ct, xray': 'ct',\n",
    "    'ct ': 'ct',\n",
    "    'ct colonography ': 'ct',\n",
    "    'ovarian': 'ovarian',\n",
    "    ' ct angiography': 'angiography',\n",
    "    'ct function and morphology ': 'ct',\n",
    "    'ct enteroclysis': 'ct',\n",
    "    'petct': 'pet-ct',\n",
    "    'colonography ': 'gi imaging',\n",
    "    '  ct angiography': 'angiography',\n",
    "    'ct head venography': 'ct',\n",
    "    'ct cystography': 'ct',\n",
    "    'ct maxface ': 'ct',\n",
    "    'nuclear bone scan': 'nuclear scan',\n",
    "    'biopsy': 'biopsy',\n",
    "    'ct functionand morphology': 'ct'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b731f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mapping_dict = {\n",
    "    'ct': 'ct',\n",
    "    None: 'unknown',\n",
    "    'ct angiography': 'angiography',\n",
    "    'ct arthrography': 'ct',\n",
    "    'ct function and morphology': 'ct',\n",
    "    'ct maxillofacial': 'ct',\n",
    "    'ct maxface': 'ct',\n",
    "    'ct venography': 'ct',\n",
    "    'ct angiography-perfusion': 'angiography',\n",
    "    'ct colonography': 'ct',\n",
    "    'ct enterography': 'ct',\n",
    "    'lumbar nerve root block': 'nerve injection',\n",
    "    'xray': 'xray',\n",
    "    'ct high resolution': 'ct',\n",
    "    'ct quantitative': 'ct',\n",
    "    'ct urography': 'ct',\n",
    "    'mri': 'mri',\n",
    "    'ultrasound': 'ultrasound',\n",
    "    'follow up ': 'follow-up',\n",
    "    'intestine': 'gi imaging',\n",
    "    'epidural steroid injection': 'nerve injection',\n",
    "    'ct, xray': 'ct',\n",
    "    'ct ': 'ct',\n",
    "    'ct colonography ': 'ct',\n",
    "    'ovarian': 'ovarian',\n",
    "    ' ct angiography': 'angiography',\n",
    "    'ct function and morphology ': 'ct',\n",
    "    'ct enteroclysis': 'ct',\n",
    "    'petct': 'pet-ct',\n",
    "    'colonography ': 'gi imaging',\n",
    "    '  ct angiography': 'angiography',\n",
    "    'ct head venography': 'ct',\n",
    "    'ct cystography': 'ct',\n",
    "    'ct maxface ': 'ct',\n",
    "    'nuclear bone scan': 'nuclear scan',\n",
    "    'biopsy': 'biopsy',\n",
    "    'ct functionand morphology': 'ct'\n",
    "}\n",
    "\n",
    "data['clinician_exam_flags'] = data['clinician_exam_flags'].fillna(-1)\n",
    "data['claude_exam_flags'] = data['claude_exam_flags'].fillna(-1)\n",
    "data['chatGPT_exam_flags'] = data['chatGPT_exam_flags'].fillna(-1)\n",
    "data['clinician_exam_flags'] = data['clinician_exam_flags'].astype('int64')\n",
    "data['claude_exam_flags'] = data['claude_exam_flags'].astype('int64')\n",
    "data['chatGPT_exam_flags'] = data['chatGPT_exam_flags'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dac8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modalities = [ \n",
    "    'ct', np.nan, 'ct angiography', 'ct arthrography',\n",
    "    'ct function and morphology', 'ct maxillofacial', 'ct maxface',\n",
    "    'ct venography', 'ct angiography-perfusion', 'ct colonography',\n",
    "    'ct enterography', 'lumbar nerve root block', 'xray',\n",
    "    'ct high resolution', 'ct quantitative', 'ct urography', 'mri',\n",
    "    'ultrasound', 'follow up ', 'intestine',\n",
    "    'epidural steroid injection', 'ct, xray', 'ct ',\n",
    "    'ct colonography ', 'ovarian', ' ct angiography',\n",
    "    'ct function and morphology ', 'ct enteroclysis', 'petct',\n",
    "    'colonography ', '  ct angiography', 'ct head venography',\n",
    "    'ct cystography', 'ct maxface ', 'nuclear bone scan', 'biopsy',\n",
    "    'ct functionand morphology'\n",
    "]\n",
    "\n",
    "# Define mapping function\n",
    "def map_to_cy(value):\n",
    "    \"\"\"\n",
    "    Map exam / modality strings to one of: 'angiography', 'ct', 'other'.\n",
    "    Anything unparseable becomes np.nan.\n",
    "    \"\"\"\n",
    "    # Handle missing\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "\n",
    "    # Coerce everything to str *safely*\n",
    "    try:\n",
    "        text = str(value).strip().lower()\n",
    "    except Exception:          # e.g. list, dict\n",
    "        return np.nan\n",
    "\n",
    "    if \"angiography\" in text:\n",
    "        return \"angiography\"\n",
    "    elif \"ct\" in text:\n",
    "        return \"ct\"\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "\n",
    "# Apply mapping\n",
    "mapped_modalities = list(map(map_to_cy, modalities))\n",
    "\n",
    "data['test_type'] = data['ESR_iGuide_exam'].map(map_to_cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaee2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the clusters and the tokenize_and_flag function as we established above\n",
    "clusters = {\n",
    "    \"head\": [\"head\", \"cranial\", \"skull\", \"brain\", \"cerebral\", \"facial\", \"sinus\", \"paranasal sinuses\", \"temporal bone\", \n",
    "             \"face\", \"orbit\", \"temporomandibular joints\", \"maxilla\", \"sinuses\", \"mandible\", \"pituitary gland\", \n",
    "             \"maxillofacial area\", \"maxillofacial\", \"nasopharynx\",  \"salivary glands\", \"maxillofacial region\", \n",
    "             \"mouth area\", 'tongue', 'scalp', 'pituitary', 'eye', 'intracranial', \"ear\", \"temporomandibular joint\"],\n",
    "    \"neck\": [\"neck\", \"cervical\", \"throat\", \"nuchal\", \"larynx\", \"esophagus\", \"carotid arteries\", \"carotid\", \"parotid gland\", \"thyroid\"],\n",
    "    \"thorax\": [\"thorax\", \"chest\", \"thoracic\", \"pulmonary\", \"heart\", \"cardiac\", \"breast\", \"mediastinum\", \"aorta\", \n",
    "               \"aortic\", \"coronary\", \"coronaries\", \"aorta branches\", \"sternoclavicular joint\", \"breasts\", \"trachea\", \"lung\", \"lungs\", \"clavicula\", \"scapula bone\",\n",
    "               \"joint sternoclavicular\", \"subclavian artery\", \"coronary arteries\"],\n",
    "    \"abdomen_pelvis\": [\"abdomen\", \"abdominal\", \"stomach\", \"intestinal\", \"gastrointestinal\", \"liver\", \"pancreas\", \"spleen\", \"small bowel\", \"colon\", \n",
    "                       \"colonography colon\", \"gallbladder\", \"kidney\", \"kidneys\", \"urinary organs\", \"biliary tract\", \"biliary system\", \"renal\", \"adrenal\",\n",
    "                       \"adrenal gland\", \"adrenal glands\", \"pelvis\", \"pelvic\", \"hip\", \"inguinal\", \"pubic\", \"iliac vein\", \"urinary bladder\", \"urinary tract\", \"prostate\",\n",
    "                       \"uterus\", \"uterus and ovaries\"],\n",
    "    \"upper_extremities\": [\"upper\", \"arm\", \"shoulder\", \"elbow\", \"wrist\", \"hand\", \"scapula\", \"clavicle\", \n",
    "                          \"humerus\", \"right humerus\", \"ulna left\", \"forearm\", \"left forearm\", \"finger\", 'brachial plexus', \"right thumb\"],\n",
    "    \"lower_extremities\": [\"lower\", \"leg\", \"knee\", \"knees\", \"foot\", \"thigh\", \"tibia\", \"femur\", \"calcaneus\", \n",
    "                          \"popliteal artery\", \"knees bilateral\", \"right malleolus\", 'femoral nerve left', \"lower extremities\", \"iliofemoral arteries\", \"ankle\"],\n",
    "    \"spine\": [\"spine\", \"vertebral\", \"lumbar\", \"sacral\", \"spinal canal\", \"spinal cord\", \"spinal\", \"thoracic spine\"],\n",
    "    \"skeletal\": [\"joint\", \"bone\", \"bones\", \"skeletal\", \"skeleton\", \"extremities\", \"musculoskeletal\", \"musculoskeletal system\"],\n",
    "    \"lymphatic\": [\"lymph nodes\", \"lymphatic system\"],\n",
    "    \"body\": [\"whole body\", \"body\", 'full body', 'various organs', 'multiple organs',\n",
    "              \"extremities\", \"multiple organ systems\", 'muscular system', 'skin', 'limbs', \"blood\", \"peripheral\", 'endocrine system', \"muscles\",\n",
    "              \"vascular region\", \"vascular system\", \"arterial system\"]\n",
    "}\n",
    "\n",
    "def tokenize_and_flag(phrase):\n",
    "    if pd.isna(phrase):\n",
    "        return None\n",
    "    cleaned_phrase = re.sub(r\"-\", \" \", str(phrase))\n",
    "    cleaned_phrase = re.sub(r\"[^\\w\\s]\", \"\", cleaned_phrase.lower())\n",
    "    binary_flag = 0\n",
    "    cluster_tokens = {\n",
    "        \"head\": 1 << 0, \"neck\": 1 << 1, \"thorax\": 1 << 2, \"abdomen_pelvis\": 1 << 3,\n",
    "        \"upper_extremities\": 1 << 4, \"lower_extremities\": 1 << 5, \"spine\": 1 << 6,\n",
    "        \"skeletal\": 1 << 7, \"lymphatic\": 1 << 8, \"body\": 1 << 9\n",
    "    }\n",
    "    for cluster, terms in clusters.items():\n",
    "        if any(re.search(r\"\\b\" + re.escape(term) + r\"\\b\", cleaned_phrase) for term in terms):\n",
    "            binary_flag |= cluster_tokens[cluster]\n",
    "    return binary_flag\n",
    "\n",
    "\n",
    "\n",
    "data['clinician_organ_flags'] = data['clinician_organ'].apply(tokenize_and_flag)\n",
    "data['ESR_iGuide_organ_flags'] = data['ESR_iGuide_organ'].apply(tokenize_and_flag)\n",
    "data['claude_organ_flags'] = data['claude_organ'].apply(tokenize_and_flag)\n",
    "data['chatGPT_organ_flags'] = data['chatGPT_organ'].apply(tokenize_and_flag)\n",
    "\n",
    "data['clinician_organ_flags'] = data['clinician_organ_flags'].fillna(-1)\n",
    "data['claude_organ_flags'] = data['claude_organ_flags'].fillna(-1)\n",
    "data['chatGPT_organ_flags'] = data['chatGPT_organ_flags'].fillna(-1)\n",
    "\n",
    "data['clinician_organ_flags'] = data['clinician_organ_flags'].astype('int64')\n",
    "data['claude_organ_flags'] = data['claude_organ_flags'].astype('int64')\n",
    "data['chatGPT_organ_flags'] = data['chatGPT_organ_flags'].astype('int64')\n",
    "\n",
    "\n",
    "data = data.dropna(subset=['ESR_iGuide_contrast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1edb559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping for standardizing contrast descriptions\n",
    "contrast_columns = ['ESR_iGuide_contrast', 'clinician_contrast', 'claude_contrast', 'chatGPT_contrast']\n",
    "\n",
    "contrast_standardization_map = {\n",
    "'with iv contrast ': 'with iv contrast', \n",
    "'without iv contrast '\n",
    "'without iv contrast ':'without iv contrast',\n",
    "'without iv contrast_x000D_':'without iv contrast',\n",
    "'no iv contrast':'without iv contrast',\n",
    "' with iv contrast': 'with iv contrast',\n",
    " 'with iv contrast ':'with iv contrast',\n",
    " \n",
    "       ' with or without iv contrast':'with or without iv contrast', \n",
    "       ' without iv contrast': 'without iv contrast',\n",
    "       'with or without iv contrast ':'with or without iv contrast',\n",
    "       ' with iv contrast': 'with iv contrast',\n",
    "       'with or without iv contrast ':'with or without iv contrast', \n",
    "       ' with or without iv contrast': 'with or without iv contrast',\n",
    "       ' without iv contrast': 'without iv contrast',\n",
    "       'wo /w iv contrast': 'with or without iv contrast',\n",
    "       'w iv contras': 'with iv contrast',\n",
    "     'w iv contrast': 'with iv contrast', \n",
    "     'wo/w iv contrast': 'with or without iv contrast',\n",
    "       'wo/with iv contrast': 'with or without iv contrast',\n",
    "         'wo /w iv contrast': 'with or without iv contrast',\n",
    "       \n",
    "       'w/without iv contrast': 'with or without iv contrast',\n",
    "        'wo iv. contrast' :'without iv contrast',\n",
    "       'wo iv contarast': 'without iv contrast',\n",
    "         'w contrast':'with iv contrast',\n",
    "           'w iv contrast  ':'with iv contrast',\n",
    "       'wo in contrast':'with iv contrast',\n",
    "       'w iv contrast ':'without iv contrast', \n",
    "       'wo/w. iv contrast': 'with or without iv contrast',\n",
    "       'w i.v. contrast':'with iv contrast', \n",
    "       'w iv contrat':'with iv contrast',\n",
    "         'wo contrast':'without iv contrast',\n",
    "       'w. iv contrast':'with iv contrast',\n",
    "       'wo i.v. contrast':'without iv contrast',\n",
    "       'wo/w i.v. contrast': 'with or without iv contrast',\n",
    "       'wo/w iv contrast ': 'with or without iv contrast',\n",
    "       'w ic contrast ':'with iv contrast',\n",
    "       'without iv contrast ':'without iv contrast'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "# Function to apply standardization\n",
    "def standardize_contrast(column):\n",
    "    return column.map(contrast_standardization_map).fillna(column)\n",
    "\n",
    "# Apply the standardization function to the contrast columns\n",
    "for col in contrast_columns:\n",
    "    data[col] = standardize_contrast(data[col])\n",
    "\n",
    "\n",
    "def encode_binary_flags(df, column):\n",
    "    df[column + '_flags'] = df[column].map({\n",
    "        'with iv contrast': 1,\n",
    "        'without iv contrast': 0,\n",
    "        'with or without iv contrast': 2  # or another suitable encoding\n",
    "    })\n",
    "\n",
    "for col in [ 'ESR_iGuide_contrast', 'clinician_contrast','claude_contrast', 'chatGPT_contrast']:\n",
    "    encode_binary_flags(data, col)\n",
    "\n",
    "\n",
    "\n",
    "data['clinician_contrast_flags'] = data['clinician_contrast_flags'].fillna(-1)\n",
    "data['claude_contrast_flags'] = data['claude_contrast_flags'].fillna(-1)\n",
    "data['chatGPT_contrast_flags'] = data['chatGPT_contrast_flags'].fillna(-1)\n",
    "\n",
    "\n",
    "data['clinician_contrast_flags'] = data['clinician_contrast_flags'].astype('int64')\n",
    "data['claude_contrast_flags'] = data['claude_contrast_flags'].astype('int64')\n",
    "data['chatGPT_contrast_flags'] = data['chatGPT_contrast_flags'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7bf2c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def group_permutation_p_value(y_true_a, y_pred_a,\n",
    "                              y_true_b, y_pred_b,\n",
    "                              metric_func=accuracy_score,\n",
    "                              n_permutations=1000):\n",
    "    \"\"\"\n",
    "    Permutation p-value for the difference of `metric_func`\n",
    "    between subset A and subset B.\n",
    "    \"\"\"\n",
    "    # ❶ Drop -1 labels\n",
    "    m_a = (y_true_a != -1) & (y_pred_a != -1)\n",
    "    m_b = (y_true_b != -1) & (y_pred_b != -1)\n",
    "    y_true_a, y_pred_a = y_true_a[m_a], y_pred_a[m_a]\n",
    "    y_true_b, y_pred_b = y_true_b[m_b], y_pred_b[m_b]\n",
    "\n",
    "    if len(y_true_a) == 0 or len(y_true_b) == 0:\n",
    "        return np.nan          # nothing to compare\n",
    "\n",
    "    # ❷ Observed gap (B – A)\n",
    "    obs_gap = metric_func(y_true_b, y_pred_b) - metric_func(y_true_a, y_pred_a)\n",
    "\n",
    "    # ❸ Pool and permute\n",
    "    y_true_pool = np.concatenate([y_true_a, y_true_b])\n",
    "    y_pred_pool = np.concatenate([y_pred_a, y_pred_b])\n",
    "    n_a = len(y_true_a)\n",
    "\n",
    "    hits = 0\n",
    "    for _ in range(n_permutations):\n",
    "        perm_idx = np.random.permutation(len(y_true_pool))\n",
    "        a_idx, b_idx = perm_idx[:n_a], perm_idx[n_a:]\n",
    "        perm_gap = (metric_func(y_true_pool[b_idx], y_pred_pool[b_idx]) -\n",
    "                    metric_func(y_true_pool[a_idx], y_pred_pool[a_idx]))\n",
    "        if abs(perm_gap) >= abs(obs_gap):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / n_permutations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e068a3",
   "metadata": {},
   "source": [
    "#### by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b133b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 0 .  Setup  (make sure these columns exist in exam_data)\n",
    "# --------------------------------------------------------------\n",
    "entries = {\n",
    "    'exam': ['ESR_iGuide_exam_flags','clinician_exam_flags','chatGPT_exam_flags','claude_exam_flags'], \n",
    "    'organ':['ESR_iGuide_organ_flags','clinician_organ_flags','chatGPT_organ_flags','claude_organ_flags',], \n",
    "    'contrast': ['ESR_iGuide_contrast_flags','clinician_contrast_flags','chatGPT_contrast_flags','claude_contrast_flags']\n",
    "}\n",
    "\n",
    "# Metric functions you care about\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "METRICS = {\n",
    "    'accuracy':  accuracy_score,\n",
    "    'precision': lambda y, p: precision_score(y, p, average='weighted', zero_division=0),\n",
    "    'recall':    lambda y, p: recall_score(y, p, average='weighted', zero_division=0),\n",
    "    'f1':        lambda y, p: f1_score(y, p, average='weighted', zero_division=0),\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1 .  Slice the two modality subsets *once*\n",
    "# --------------------------------------------------------------\n",
    "ct_df  = data[data['sex'] == 'm']\n",
    "ang_df = data[data['sex'] == 'f']\n",
    "\n",
    "if ct_df.empty or ang_df.empty:\n",
    "    raise ValueError(\"Need at least one CT and one angiography row.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2 .  Permutation helper (unchanged)\n",
    "# --------------------------------------------------------------\n",
    "def permutation_gap_pvalue(y_true_a, y_pred_a,\n",
    "                           y_true_b, y_pred_b,\n",
    "                           metric_func, n_permutations=1000):\n",
    "    m_a = (y_true_a != -1) & (y_pred_a != -1)\n",
    "    m_b = (y_true_b != -1) & (y_pred_b != -1)\n",
    "    y_true_a, y_pred_a = y_true_a[m_a], y_pred_a[m_a]\n",
    "    y_true_b, y_pred_b = y_true_b[m_b], y_pred_b[m_b]\n",
    "\n",
    "    if len(y_true_a) == 0 or len(y_true_b) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    obs_gap = metric_func(y_true_b, y_pred_b) - metric_func(y_true_a, y_pred_a)\n",
    "\n",
    "    y_true_pool = np.concatenate([y_true_a, y_true_b])\n",
    "    y_pred_pool = np.concatenate([y_pred_a, y_pred_b])\n",
    "    n_a = len(y_true_a)\n",
    "\n",
    "    hits = 0\n",
    "    for _ in range(n_permutations):\n",
    "        perm_idx = np.random.permutation(len(y_true_pool))\n",
    "        a_idx, b_idx = perm_idx[:n_a], perm_idx[n_a:]\n",
    "        perm_gap = (metric_func(y_true_pool[b_idx], y_pred_pool[b_idx]) -\n",
    "                    metric_func(y_true_pool[a_idx], y_pred_pool[a_idx]))\n",
    "        if abs(perm_gap) >= abs(obs_gap):\n",
    "            hits += 1\n",
    "    return hits / n_permutations\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3 .  Run for every model × metric\n",
    "# --------------------------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "# 3 .  Run for every entry (exam / organ / contrast) × model × metric\n",
    "# --------------------------------------------------------------\n",
    "rows = []\n",
    "N_PERM = 1_000           # permutations; raise if you need more precision\n",
    "\n",
    "for entry_name, cols in entries.items():\n",
    "    y_true_col  = cols[0]     # ESR_iGuide_* column\n",
    "    model_cols  = cols[1:]    # clinician / chatGPT / claude\n",
    "\n",
    "    for pred_col in model_cols:\n",
    "        # Make a short model label: clinician_exam_flags ➜ clinician, etc.\n",
    "        model_name = pred_col.split('_')[0]\n",
    "\n",
    "        for metric_name, metric_func in METRICS.items():   # <-- .items() !!\n",
    "            p_val = permutation_gap_pvalue(\n",
    "                ct_df[y_true_col],  ct_df[pred_col],\n",
    "                ang_df[y_true_col], ang_df[pred_col],\n",
    "                metric_func=metric_func,\n",
    "                n_permutations=N_PERM\n",
    "            )\n",
    "            rows.append({\n",
    "                'entry':   entry_name,                 # exam / organ / contrast\n",
    "                'llm':     model_name,                 # clinician / chatgpt / claude\n",
    "                'metric':  metric_name,                # accuracy / precision / …\n",
    "                'p_value_sex': p_val,\n",
    "                'n_CT':    len(ct_df),\n",
    "                'n_angio': len(ang_df),\n",
    "            })\n",
    "\n",
    "overall_gap_df = pd.DataFrame(rows)\n",
    "print(overall_gap_df.head())\n",
    "\n",
    "# optional: save\n",
    "# overall_gap_df.to_excel(r\"C:\\work\\...\\CT_vs_angio_all_models.xlsx\", index=False)\n",
    "\n",
    "# optional: save\n",
    "# overall_gap_df.to_excel(r\"C:\\work\\...\\CT_vs_angio_all_models.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81d2f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### by age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac86e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Two simple age bands ----------------------------------------------------\n",
    "cuts   = [0, 65, np.inf]        # 0 ≤ age < 65  |  65 ≤ age\n",
    "labels = ['<65','65<']         # or use '≤64' / '65+' if you prefer\n",
    "\n",
    "data['age_group'] = pd.cut(\n",
    "    data['Patient Age'].astype(float),  # make sure it’s numeric\n",
    "    bins=cuts,\n",
    "    labels=labels,\n",
    "    right=False,        # left-closed, right-open intervals\n",
    "    include_lowest=True # include age = 0 if you ever have it\n",
    ")\n",
    "\n",
    "# Quick sanity check\n",
    "print(data['age_group'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd0fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 0 .  Setup  (make sure these columns exist in exam_data)\n",
    "# --------------------------------------------------------------\n",
    "entries = {\n",
    "    'exam': ['ESR_iGuide_exam_flags','clinician_exam_flags','chatGPT_exam_flags','claude_exam_flags'], \n",
    "    'organ':['ESR_iGuide_organ_flags','clinician_organ_flags','chatGPT_organ_flags','claude_organ_flags',], \n",
    "    'contrast': ['ESR_iGuide_contrast_flags','clinician_contrast_flags','chatGPT_contrast_flags','claude_contrast_flags']\n",
    "}\n",
    "\n",
    "# Metric functions you care about\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "METRICS = {\n",
    "    'accuracy':  accuracy_score,\n",
    "    'precision': lambda y, p: precision_score(y, p, average='weighted', zero_division=0),\n",
    "    'recall':    lambda y, p: recall_score(y, p, average='weighted', zero_division=0),\n",
    "    'f1':        lambda y, p: f1_score(y, p, average='weighted', zero_division=0),\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1 .  Slice the two modality subsets *once*\n",
    "# --------------------------------------------------------------\n",
    "ct_df  = data[data['age_group'] == '65<']\n",
    "ang_df = data[data['age_group'] == '<65']\n",
    "\n",
    "if ct_df.empty or ang_df.empty:\n",
    "    raise ValueError(\"Need at least one CT and one angiography row.\")\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2 .  Permutation helper (unchanged)\n",
    "# --------------------------------------------------------------\n",
    "def permutation_gap_pvalue(y_true_a, y_pred_a,\n",
    "                           y_true_b, y_pred_b,\n",
    "                           metric_func, n_permutations=1000):\n",
    "    m_a = (y_true_a != -1) & (y_pred_a != -1)\n",
    "    m_b = (y_true_b != -1) & (y_pred_b != -1)\n",
    "    y_true_a, y_pred_a = y_true_a[m_a], y_pred_a[m_a]\n",
    "    y_true_b, y_pred_b = y_true_b[m_b], y_pred_b[m_b]\n",
    "\n",
    "    if len(y_true_a) == 0 or len(y_true_b) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    obs_gap = metric_func(y_true_b, y_pred_b) - metric_func(y_true_a, y_pred_a)\n",
    "\n",
    "    y_true_pool = np.concatenate([y_true_a, y_true_b])\n",
    "    y_pred_pool = np.concatenate([y_pred_a, y_pred_b])\n",
    "    n_a = len(y_true_a)\n",
    "\n",
    "    hits = 0\n",
    "    for _ in range(n_permutations):\n",
    "        perm_idx = np.random.permutation(len(y_true_pool))\n",
    "        a_idx, b_idx = perm_idx[:n_a], perm_idx[n_a:]\n",
    "        perm_gap = (metric_func(y_true_pool[b_idx], y_pred_pool[b_idx]) -\n",
    "                    metric_func(y_true_pool[a_idx], y_pred_pool[a_idx]))\n",
    "        if abs(perm_gap) >= abs(obs_gap):\n",
    "            hits += 1\n",
    "    return hits / n_permutations\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3 .  Run for every model × metric\n",
    "# --------------------------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "# 3 .  Run for every entry (exam / organ / contrast) × model × metric\n",
    "# --------------------------------------------------------------\n",
    "rows = []\n",
    "N_PERM = 1_000           # permutations; raise if you need more precision\n",
    "\n",
    "for entry_name, cols in entries.items():\n",
    "    y_true_col  = cols[0]     # ESR_iGuide_* column\n",
    "    model_cols  = cols[1:]    # clinician / chatGPT / claude\n",
    "\n",
    "    for pred_col in model_cols:\n",
    "        # Make a short model label: clinician_exam_flags ➜ clinician, etc.\n",
    "        model_name = pred_col.split('_')[0]\n",
    "\n",
    "        for metric_name, metric_func in METRICS.items():   # <-- .items() !!\n",
    "            p_val = permutation_gap_pvalue(\n",
    "                ct_df[y_true_col],  ct_df[pred_col],\n",
    "                ang_df[y_true_col], ang_df[pred_col],\n",
    "                metric_func=metric_func,\n",
    "                n_permutations=N_PERM\n",
    "            )\n",
    "            rows.append({\n",
    "                'entry':   entry_name,                 # exam / organ / contrast\n",
    "                'llm':     model_name,                 # clinician / chatgpt / claude\n",
    "                'metric':  metric_name,                # accuracy / precision / …\n",
    "                'p_value_age_cut_65': p_val,\n",
    "                'n_CT':    len(ct_df),\n",
    "                'n_angio': len(ang_df),\n",
    "            })\n",
    "\n",
    "overall_gap_df = pd.DataFrame(rows)\n",
    "print(overall_gap_df.head())\n",
    "\n",
    "# optional: save\n",
    "# overall_gap_df.to_excel(r\"C:\\work\\...\\CT_vs_angio_all_models.xlsx\", index=False)\n",
    "\n",
    "# optional: save\n",
    "# overall_gap_df.to_excel(r\"C:\\work\\...\\CT_vs_angio_all_models.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c76ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 0.  Setup (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "entries = {\n",
    "    'exam':     ['ESR_iGuide_exam_flags',\n",
    "                 'clinician_exam_flags', 'chatGPT_exam_flags', 'claude_exam_flags'],\n",
    "    'organ':    ['ESR_iGuide_organ_flags',\n",
    "                 'clinician_organ_flags', 'chatGPT_organ_flags', 'claude_organ_flags'],\n",
    "    'contrast': ['ESR_iGuide_contrast_flags',\n",
    "                 'clinician_contrast_flags', 'chatGPT_contrast_flags', 'claude_contrast_flags']\n",
    "}\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "METRICS = {\n",
    "    'accuracy':  accuracy_score,\n",
    "    'precision': lambda y, p: precision_score(y, p, average='weighted', zero_division=0),\n",
    "    'recall':    lambda y, p: recall_score(y, p, average='weighted', zero_division=0),\n",
    "    'f1':        lambda y, p: f1_score(y, p, average='weighted', zero_division=0),\n",
    "}\n",
    "\n",
    "SEX_COL   = \"sex\"          # adjust if your column is named differently\n",
    "N_PERM    = 1_000          # raise for finer p-value resolution\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Permutation helper (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "def permutation_gap_pvalue(y_true_a, y_pred_a,\n",
    "                           y_true_b, y_pred_b,\n",
    "                           metric_func, n_permutations=N_PERM):\n",
    "    m_a = (y_true_a != -1) & (y_pred_a != -1)\n",
    "    m_b = (y_true_b != -1) & (y_pred_b != -1)\n",
    "    y_true_a, y_pred_a = y_true_a[m_a], y_pred_a[m_a]\n",
    "    y_true_b, y_pred_b = y_true_b[m_b], y_pred_b[m_b]\n",
    "\n",
    "    if len(y_true_a) == 0 or len(y_true_b) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    obs_gap = metric_func(y_true_b, y_pred_b) - metric_func(y_true_a, y_pred_a)\n",
    "\n",
    "    y_true_pool = np.concatenate([y_true_a, y_true_b])\n",
    "    y_pred_pool = np.concatenate([y_pred_a, y_pred_b])\n",
    "    n_a = len(y_true_a)\n",
    "\n",
    "    hits = 0\n",
    "    for _ in range(n_permutations):\n",
    "        perm_idx = np.random.permutation(len(y_true_pool))\n",
    "        a_idx, b_idx = perm_idx[:n_a], perm_idx[n_a:]\n",
    "        perm_gap = (metric_func(y_true_pool[b_idx], y_pred_pool[b_idx]) -\n",
    "                    metric_func(y_true_pool[a_idx], y_pred_pool[a_idx]))\n",
    "        if abs(perm_gap) >= abs(obs_gap):\n",
    "            hits += 1\n",
    "    return hits / n_permutations\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Female vs Male  inside each test-type\n",
    "# ------------------------------------------------------------------\n",
    "rows = []\n",
    "\n",
    "for test_name, test_df in data.groupby('test_type', observed=True):\n",
    "    fem_df  = test_df[test_df[SEX_COL] == 'f']\n",
    "    male_df = test_df[test_df[SEX_COL] == 'm']\n",
    "    if fem_df.empty or male_df.empty:        # need both sexes present\n",
    "        continue\n",
    "\n",
    "    for entry_name, cols in entries.items():\n",
    "        y_true_col = cols[0]\n",
    "        model_cols = cols[1:]\n",
    "\n",
    "        for pred_col in model_cols:\n",
    "            model_name = pred_col.split('_')[0]   # clinician / chatGPT / claude\n",
    "\n",
    "            for metric_name, metric_func in METRICS.items():\n",
    "                p_val = permutation_gap_pvalue(\n",
    "                    fem_df[y_true_col],  fem_df[pred_col],\n",
    "                    male_df[y_true_col], male_df[pred_col],\n",
    "                    metric_func=metric_func\n",
    "                )\n",
    "                rows.append({\n",
    "                    'test_type': test_name,            # ct / angiography / …\n",
    "                    'entry':     entry_name,           # exam / organ / contrast\n",
    "                    'llm':       model_name,           # clinician / chatgpt / claude\n",
    "                    'metric':    metric_name,          # accuracy / precision / …\n",
    "                    'p_value_female_vs_male': p_val,\n",
    "                    'n_female':  len(fem_df),\n",
    "                    'n_male':    len(male_df),\n",
    "                })\n",
    "\n",
    "overall_gap_df = pd.DataFrame(rows)\n",
    "print(overall_gap_df.head())\n",
    "\n",
    "# optional:\n",
    "# overall_gap_df.to_excel(r\"C:\\work\\...\\female_vs_male_all_models.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7978996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# 0.  Setup (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "entries = {\n",
    "    'exam':     ['ESR_iGuide_exam_flags',\n",
    "                 'clinician_exam_flags', 'chatGPT_exam_flags', 'claude_exam_flags'],\n",
    "    'organ':    ['ESR_iGuide_organ_flags',\n",
    "                 'clinician_organ_flags', 'chatGPT_organ_flags', 'claude_organ_flags'],\n",
    "    'contrast': ['ESR_iGuide_contrast_flags',\n",
    "                 'clinician_contrast_flags', 'chatGPT_contrast_flags', 'claude_contrast_flags']\n",
    "}\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "METRICS = {\n",
    "    'accuracy':  accuracy_score,\n",
    "    'precision': lambda y, p: precision_score(y, p, average='weighted', zero_division=0),\n",
    "    'recall':    lambda y, p: recall_score(y, p, average='weighted', zero_division=0),\n",
    "    'f1':        lambda y, p: f1_score(y, p, average='weighted', zero_division=0),\n",
    "}\n",
    "\n",
    "SEX_COL   = \"age_group\"          # adjust if your column is named differently\n",
    "N_PERM    = 1_000          # raise for finer p-value resolution\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1.  Permutation helper (unchanged)\n",
    "# ------------------------------------------------------------------\n",
    "def permutation_gap_pvalue(y_true_a, y_pred_a,\n",
    "                           y_true_b, y_pred_b,\n",
    "                           metric_func, n_permutations=N_PERM):\n",
    "    m_a = (y_true_a != -1) & (y_pred_a != -1)\n",
    "    m_b = (y_true_b != -1) & (y_pred_b != -1)\n",
    "    y_true_a, y_pred_a = y_true_a[m_a], y_pred_a[m_a]\n",
    "    y_true_b, y_pred_b = y_true_b[m_b], y_pred_b[m_b]\n",
    "\n",
    "    if len(y_true_a) == 0 or len(y_true_b) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    obs_gap = metric_func(y_true_b, y_pred_b) - metric_func(y_true_a, y_pred_a)\n",
    "\n",
    "    y_true_pool = np.concatenate([y_true_a, y_true_b])\n",
    "    y_pred_pool = np.concatenate([y_pred_a, y_pred_b])\n",
    "    n_a = len(y_true_a)\n",
    "\n",
    "    hits = 0\n",
    "    for _ in range(n_permutations):\n",
    "        perm_idx = np.random.permutation(len(y_true_pool))\n",
    "        a_idx, b_idx = perm_idx[:n_a], perm_idx[n_a:]\n",
    "        perm_gap = (metric_func(y_true_pool[b_idx], y_pred_pool[b_idx]) -\n",
    "                    metric_func(y_true_pool[a_idx], y_pred_pool[a_idx]))\n",
    "        if abs(perm_gap) >= abs(obs_gap):\n",
    "            hits += 1\n",
    "    return hits / n_permutations\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2.  Female vs Male  inside each test-type\n",
    "# ------------------------------------------------------------------\n",
    "rows = []\n",
    "\n",
    "for test_name, test_df in data.groupby('test_type', observed=True):\n",
    "    fem_df  = test_df[test_df[SEX_COL] == '<65']\n",
    "    male_df = test_df[test_df[SEX_COL] == '65<']\n",
    "    if fem_df.empty or male_df.empty:        # need both sexes present\n",
    "        continue\n",
    "\n",
    "    for entry_name, cols in entries.items():\n",
    "        y_true_col = cols[0]\n",
    "        model_cols = cols[1:]\n",
    "\n",
    "        for pred_col in model_cols:\n",
    "            model_name = pred_col.split('_')[0]   # clinician / chatGPT / claude\n",
    "\n",
    "            for metric_name, metric_func in METRICS.items():\n",
    "                p_val = permutation_gap_pvalue(\n",
    "                    fem_df[y_true_col],  fem_df[pred_col],\n",
    "                    male_df[y_true_col], male_df[pred_col],\n",
    "                    metric_func=metric_func\n",
    "                )\n",
    "                rows.append({\n",
    "                    'test_type': test_name,            # ct / angiography / …\n",
    "                    'entry':     entry_name,           # exam / organ / contrast\n",
    "                    'llm':       model_name,           # clinician / chatgpt / claude\n",
    "                    'metric':    metric_name,          # accuracy / precision / …\n",
    "                    'p_value_age_group': p_val,\n",
    "                    'n_female':  len(fem_df),\n",
    "                    'n_male':    len(male_df),\n",
    "                })\n",
    "\n",
    "overall_gap_df = pd.DataFrame(rows)\n",
    "print(overall_gap_df.head())\n",
    "\n",
    "# optional:\n",
    "# overall_gap_df.to_excel(r\"C:\\work\\...\\female_vs_male_all_models.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "RNG      = np.random.default_rng(seed=42)   # reproducible bootstrap\n",
    "N_BOOT   = 1_000                            # raise for tighter CIs\n",
    "ALPHA    = 0.95\n",
    "OUT_DIR  = Path\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 1.  Column groups and metric dict\n",
    "# --------------------------------------------------------------\n",
    "entries = {\n",
    "    'exam'    : ['ESR_iGuide_exam_flags','clinician_exam_flags','chatGPT_exam_flags','claude_exam_flags'],\n",
    "    'organ'   : ['ESR_iGuide_organ_flags','clinician_organ_flags','chatGPT_organ_flags','claude_organ_flags'],\n",
    "    'contrast': ['ESR_iGuide_contrast_flags','clinician_contrast_flags','chatGPT_contrast_flags','claude_contrast_flags'],\n",
    "}\n",
    "\n",
    "METRICS = {\n",
    "    'accuracy' : accuracy_score,\n",
    "    'precision': lambda y, p: precision_score(y, p, average='weighted', zero_division=0),\n",
    "    'recall'   : lambda y, p: recall_score(y, p, average='weighted', zero_division=0),\n",
    "    'f1'       : lambda y, p: f1_score(y, p, average='weighted', zero_division=0),\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 2.  Helper to get point estimate + bootstrap CI\n",
    "# --------------------------------------------------------------\n",
    "def metric_with_ci(y_true, y_pred, metric_func, n_boot=N_BOOT, alpha=ALPHA):\n",
    "    point = metric_func(y_true, y_pred)\n",
    "    if n_boot == 0:\n",
    "        return point, np.nan, np.nan\n",
    "\n",
    "    boot_stats = []\n",
    "    n = len(y_true)\n",
    "    for _ in range(n_boot):\n",
    "        idx = RNG.integers(0, n, n)        # sample w. replacement\n",
    "        boot_stats.append(metric_func(y_true[idx], y_pred[idx]))\n",
    "    low, high = np.percentile(boot_stats, [(1-alpha)/2*100, (1+(alpha))/2*100])\n",
    "    return point, low, high\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3-A.  CT  vs  CT-angiography ─ metrics & CIs\n",
    "# --------------------------------------------------------------\n",
    "ct_df  = data.loc[data['test_type'] == 'ct']\n",
    "cta_df = data.loc[data['test_type'] == 'angiography']\n",
    "if ct_df.empty or cta_df.empty:\n",
    "    raise ValueError(\"Need at least one CT and one angiography row.\")\n",
    "\n",
    "rows_test = []\n",
    "for entry_name, cols in entries.items():\n",
    "    y_true_col  = cols[0]        # ESR ground-truth flags\n",
    "    for pred_col in cols[1:]:\n",
    "        model = pred_col.split('_')[0]\n",
    "        for m_name, m_func in METRICS.items():\n",
    "            # CT\n",
    "            est_ct, lo_ct, hi_ct = metric_with_ci(\n",
    "                ct_df[y_true_col].values,  ct_df[pred_col].values,  m_func\n",
    "            )\n",
    "            # CTA\n",
    "            est_cta, lo_cta, hi_cta = metric_with_ci(\n",
    "                cta_df[y_true_col].values, cta_df[pred_col].values, m_func\n",
    "            )\n",
    "\n",
    "            rows_test.append({\n",
    "                'entry'   : entry_name,\n",
    "                'model'   : model,\n",
    "                'metric'  : m_name,\n",
    "                'group'   : 'CT',           'est' : est_ct,  'ci_low': lo_ct,  'ci_high': hi_ct,\n",
    "            })\n",
    "            rows_test.append({\n",
    "                'entry'   : entry_name,\n",
    "                'model'   : model,\n",
    "                'metric'  : m_name,\n",
    "                'group'   : 'CTA',          'est' : est_cta, 'ci_low': lo_cta, 'ci_high': hi_cta,\n",
    "            })\n",
    "\n",
    "df_test = pd.DataFrame(rows_test)\n",
    "df_test.to_excel(OUT_DIR / \"metrics_CT_vs_CTA.xlsx\", index=False)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 3-B.  Age (<65  vs  ≥65) ─ metrics & CIs\n",
    "# --------------------------------------------------------------\n",
    "age_df = data.copy()\n",
    "age_df['age_bin'] = np.where(age_df['Patient Age'] < 65, '<65', '≥65')\n",
    "\n",
    "rows_age = []\n",
    "for entry_name, cols in entries.items():\n",
    "    y_true_col  = cols[0]\n",
    "    for pred_col in cols[1:]:\n",
    "        model = pred_col.split('_')[0]\n",
    "        for m_name, m_func in METRICS.items():\n",
    "            for grp, g in age_df.groupby('age_bin'):\n",
    "                est, lo, hi = metric_with_ci(g[y_true_col].values, g[pred_col].values, m_func)\n",
    "                rows_age.append({\n",
    "                    'entry': entry_name, 'model': model, 'metric': m_name,\n",
    "                    'group': grp, 'est': est, 'ci_low': lo, 'ci_high': hi\n",
    "                })\n",
    "\n",
    "df_age = pd.DataFrame(rows_age)\n",
    "df_age.to_excel(OUT_DIR / \"metrics_under65_vs_over65.xlsx\", index=False)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 4.  FIGURE 1  –  Forest / dot-whisker  (accuracy only, exam-level)\n",
    "# --------------------------------------------------------------\n",
    "plot_df = (\n",
    "    df_test\n",
    "      .query(\"entry == 'exam' and metric == 'accuracy'\")\n",
    "      .sort_values(['model', 'group'])\n",
    "      .reset_index(drop=True)          #  ← this line\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "y_pos = np.arange(len(plot_df))\n",
    "colors = {'CT':'black', 'CTA':'slategray'}\n",
    "\n",
    "for i, row in plot_df.iterrows():\n",
    "    ax.errorbar(row['est']*100,               # convert to %\n",
    "                y_pos[i],\n",
    "                xerr=[[ (row['est']-row['ci_low'])*100 ],\n",
    "                      [ (row['ci_high']-row['est'])*100 ]],\n",
    "                fmt='o', color=colors[row['group']],\n",
    "                capsize=3, markersize=5, label=row['group'] if i < 2 else \"\")\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels([f\"{r['model']}\" for _, r in plot_df.iterrows()])\n",
    "ax.set_xlabel(\"Accuracy (%)\")\n",
    "ax.set_title(\"Figure 1. CT vs CT-angiography — exam-level accuracy\")\n",
    "ax.invert_yaxis()\n",
    "ax.legend(title=\"Modality\", frameon=False, loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"Fig1_forest_CT_vs_CTA_accuracy.png\", dpi=600)\n",
    "plt.close()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# 5.  FIGURE 2  –  Grouped bar + CIs (accuracy, exam-level, <65 vs ≥65)\n",
    "# --------------------------------------------------------------\n",
    "plot_df2 = (\n",
    "    df_age\n",
    "    .query(\"entry == 'exam' and metric == 'accuracy'\")\n",
    "    .pivot_table(index=['model','group'], values=['est','ci_low','ci_high'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "x = np.arange(len(plot_df2['model'].unique()))\n",
    "bar_w = 0.35\n",
    "\n",
    "for j, grp in enumerate(['<65','≥65']):\n",
    "    grp_df = plot_df2[plot_df2['group']==grp]\n",
    "    est_pct = grp_df['est'].values*100\n",
    "    err_low = (grp_df['est'] - grp_df['ci_low']).values*100\n",
    "    err_high = (grp_df['ci_high'] - grp_df['est']).values*100\n",
    "    ax.bar(x + (j-0.5)*bar_w, est_pct, bar_w,\n",
    "           yerr=[err_low, err_high], capsize=4,\n",
    "           label=grp, color=('white' if grp=='<65' else 'lightgray'),\n",
    "           edgecolor='black')\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(grp_df['model'])\n",
    "ax.set_ylabel(\"Accuracy (%)\")\n",
    "ax.set_title(\"Figure 2. Under-65 vs ≥65 — exam-level accuracy\")\n",
    "ax.legend(title=\"Age group\", frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_DIR / \"Fig2_groupedBar_age_accuracy.png\", dpi=600)\n",
    "plt.close()\n",
    "\n",
    "print(\"✓  Metrics tables and both figures were saved in\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3097a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "#  FIGURE 1  –  one PNG per metric (organ task, CT vs CTA)\n",
    "# ------------------------------------------------------------\n",
    "METRICS_TO_PLOT = [\"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "pretty = {\"clinician\": \"Clinicians\", \"chatGPT\": \"GPT-4\", \"claude\": \"Claude\"}\n",
    "\n",
    "# tidy once\n",
    "plot_df_all = (\n",
    "    df_test\n",
    "        .query(\"entry == 'organ' and metric in @METRICS_TO_PLOT\")\n",
    "        .reset_index(drop=True)\n",
    ")\n",
    "plot_df_all[\"pretty_model\"] = plot_df_all[\"model\"].map(pretty)\n",
    "\n",
    "bar_w   = 0.35\n",
    "ct_col  = \"#181C14\"   # dark\n",
    "cta_col = \"#7D7C7C\"   # light grey\n",
    "\n",
    "for metric in METRICS_TO_PLOT:\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "\n",
    "    sub = plot_df_all.query(\"metric == @metric\")\n",
    "\n",
    "    for i, mdl in enumerate([\"Clinicians\", \"GPT-4\", \"Claude\"]):\n",
    "        # ---- CT ----\n",
    "        ct_row  = sub[(sub.pretty_model == mdl) & (sub.group == \"CT\")].iloc[0]\n",
    "        est_ct  = ct_row.est  * 100\n",
    "        err_ct  = (ct_row.ci_high - ct_row.ci_low) / 2 * 100\n",
    "        ax.bar(i - bar_w/2, est_ct, bar_w,\n",
    "               yerr=err_ct, capsize=4, color=ct_col, label=\"CT\" if i==0 else \"\")\n",
    "\n",
    "        # ---- CTA ----\n",
    "        cta_row = sub[(sub.pretty_model == mdl) & (sub.group == \"CTA\")].iloc[0]\n",
    "        est_cta = cta_row.est * 100\n",
    "        err_cta = (cta_row.ci_high - cta_row.ci_low) / 2 * 100\n",
    "        ax.bar(i + bar_w/2, est_cta, bar_w,\n",
    "               yerr=err_cta, capsize=4, color=cta_col, label=\"CTA\" if i==0 else \"\")\n",
    "\n",
    "    # cosmetics\n",
    "    ax.set_xticks(range(3))\n",
    "    ax.set_xticklabels([\"Clinicians\", \"GPT-4\", \"Claude\"], rotation=15)\n",
    "    ax.set_ylabel(\"Rate (%)\")\n",
    "    ax.set_ylim(0, 102)\n",
    "    ax.set_title(f\"{metric.capitalize()}\")\n",
    "    if metric == \"accuracy\":        # legend once (first loop iteration)\n",
    "        ax.legend(frameon=False, loc=\"upper left\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.grid(False)\n",
    "    fname = f\"Fig1_{metric}_CT_vs_CTA_organ.png\"\n",
    "    fig.savefig(OUT_DIR / fname, dpi=600)\n",
    "    plt.show(fig)\n",
    "    print(\"✓ saved\", fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a301b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "RNG         = np.random.default_rng(42)\n",
    "N_BOOT      = 1_000\n",
    "N_PERM      = 1_000\n",
    "ALPHA       = 0.95\n",
    "\n",
    "MODELS = {\"clinician\": \"Clinicians\",\n",
    "          \"chatGPT\"  : \"GPT-4\",\n",
    "          \"claude\"   : \"Claude\"}\n",
    "\n",
    "FILE    = Path \n",
    "OUT_DIR = Path\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# 2 ── helpers ─────────────────────────────────────────────────\n",
    "def bootstrap_ci(y, p):\n",
    "    \"\"\"return point, ci_lo, ci_hi (as %)\"\"\"\n",
    "    y, p = np.asarray(y), np.asarray(p)\n",
    "    point = cohen_kappa_score(y, p)\n",
    "    boot  = [cohen_kappa_score(y[RNG.integers(len(y), size=len(y))],\n",
    "                               p[RNG.integers(len(p), size=len(p))])\n",
    "             for _ in range(N_BOOT)]\n",
    "    lo, hi = np.percentile(boot, [(1-ALPHA)/2*100, (1+ALPHA)/2*100])\n",
    "    return point*100, lo*100, hi*100\n",
    "\n",
    "def perm_pvalue(y_ct, p_ct, y_cta, p_cta):\n",
    "    \"\"\"two-sided permutation p for κ gap\"\"\"\n",
    "    obs = cohen_kappa_score(y_cta, p_cta) - cohen_kappa_score(y_ct, p_ct)\n",
    "    pool_y = np.concatenate([y_ct, y_cta])\n",
    "    pool_p = np.concatenate([p_ct, p_cta])\n",
    "    n_ct   = len(y_ct)\n",
    "    hits = 0\n",
    "    for _ in range(N_PERM):\n",
    "        idx = RNG.permutation(len(pool_y))\n",
    "        gap = cohen_kappa_score(pool_y[idx[n_ct:]], pool_p[idx[n_ct:]]) - \\\n",
    "              cohen_kappa_score(pool_y[idx[:n_ct]], pool_p[idx[:n_ct]])\n",
    "        hits += abs(gap) >= abs(obs)\n",
    "    return (hits + 1) / (N_PERM + 1)\n",
    "\n",
    "# 3 ── load data ───────────────────────────────────────────────\n",
    "df = pd.read_excel(FILE)\n",
    "mask_ok = lambda y, p: (y != -1) & (p != -1)\n",
    "\n",
    "# 4 ── compute κ & p-values ────────────────────────────────────\n",
    "rows = []\n",
    "for raw, nice in MODELS.items():\n",
    "    pred_col = f\"{raw}_organ_flags\"\n",
    "\n",
    "    # split once\n",
    "    ct   = df[df[\"test_type\"] == \"ct\"]\n",
    "    cta  = df[df[\"test_type\"] == \"angiography\"]\n",
    "\n",
    "    ok_ct  = mask_ok(ct[\"ESR_iGuide_organ_flags\"],  ct[pred_col])\n",
    "    ok_cta = mask_ok(cta[\"ESR_iGuide_organ_flags\"], cta[pred_col])\n",
    "\n",
    "    # κ + CI for each modality\n",
    "    for label, data, ok in [(\"CT\", ct, ok_ct), (\"CTA\", cta, ok_cta)]:\n",
    "        kappa, lo, hi = bootstrap_ci(data[\"ESR_iGuide_organ_flags\"][ok],\n",
    "                                     data[pred_col][ok])\n",
    "        rows.append(dict(model=nice, modality=label,\n",
    "                         kappa=kappa, ci_lo=lo, ci_hi=hi))\n",
    "\n",
    "    # permutation p-value for the gap (CTA − CT)\n",
    "    p_val = perm_pvalue(ct[\"ESR_iGuide_organ_flags\"][ok_ct].values,\n",
    "                        ct[pred_col][ok_ct].values,\n",
    "                        cta[\"ESR_iGuide_organ_flags\"][ok_cta].values,\n",
    "                        cta[pred_col][ok_cta].values)\n",
    "    rows.append(dict(model=nice, modality=\"p-value\",\n",
    "                     kappa=p_val))\n",
    "\n",
    "table = pd.DataFrame(rows)\n",
    "\n",
    "# 5 ── save ────────────────────────────────────────────────────\n",
    "table.to_csv(OUT_DIR / \"kappa_CT_vs_CTA.csv\", index=False)\n",
    "print(\"✓  Cohen κ table written to\", OUT_DIR / \"kappa_CT_vs_CTA.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba689682",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RNG, N_BOOT, N_PERM, ALPHA = np.random.default_rng(42), 1_000, 1_000, .95\n",
    "\n",
    "# --- config ---\n",
    "METRICS = {\"accuracy\": accuracy_score,\n",
    "           \"precision\": lambda y,p: precision_score(y,p,average=\"weighted\",zero_division=0),\n",
    "           \"recall\":    lambda y,p: recall_score(y,p,average=\"weighted\",zero_division=0),\n",
    "           \"f1\":        lambda y,p: f1_score(y,p,average=\"weighted\",zero_division=0)}\n",
    "MODELS  = {\"clinician\":\"Clinicians\", \"chatGPT\":\"GPT-4\", \"claude\":\"Claude\"}\n",
    "FILE    = Path\n",
    "OUT_DIR = Path; OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- helpers ---\n",
    "def bootstrap_ci(y, p, func, n_boot=N_BOOT, alpha=ALPHA):\n",
    "    \"\"\"Return point estimate, low-CI, high-CI (percent scale).\"\"\"\n",
    "    # --- NEW: guarantee positional indexing ---\n",
    "    y = np.asarray(y)\n",
    "    p = np.asarray(p)\n",
    "    # ------------------------------------------\n",
    "    point = func(y, p)\n",
    "    boot_stats = []\n",
    "    n = len(y)\n",
    "    for _ in range(n_boot):\n",
    "        idx = RNG.integers(0, n, n)          # sample positions\n",
    "        boot_stats.append(func(y[idx], p[idx]))\n",
    "    lo, hi = np.percentile(\n",
    "        boot_stats, [(1-alpha)/2*100, (1+alpha)/2*100]\n",
    "    )\n",
    "    return point*100, lo*100, hi*100\n",
    "\n",
    "\n",
    "def stars(p): return \"★★★\" if p<.001 else (\"★★\" if p<.01 else (\"★\" if p<.05 else \"\"))\n",
    "\n",
    "# --- load & basic wrangling ---\n",
    "df = pd.read_excel(FILE)\n",
    "df[\"age_bin\"] = np.where(df[\"Patient Age\"]<65, \"<65\", \"≥65\")\n",
    "mask = lambda y,p: (y != -1) & (p != -1)\n",
    "row_colors = sns.color_palette('Greys', len(METRICS)) \n",
    "# -------------------------------------------------------------\n",
    "#  Build tidy table for one grouping variable (age OR sex)\n",
    "# -------------------------------------------------------------\n",
    "def build_table(group_var, groups):\n",
    "    recs=[]\n",
    "    for raw, nice in MODELS.items():\n",
    "        pred = f\"{raw}_organ_flags\"\n",
    "        for mname, mfunc in METRICS.items():\n",
    "            for grp in groups:\n",
    "                for sex in [\"Female\",\"Male\"] if group_var==\"Patient Sex\" else [grp]:\n",
    "                    # CT & CTA separately\n",
    "                    for mod in [\"ct\",\"angiography\"]:\n",
    "                        g = df[(df[group_var]==grp) & (df[\"test_type\"]==mod)]\n",
    "                        good = mask(g[\"ESR_iGuide_organ_flags\"], g[pred])\n",
    "                        est, lo, hi = bootstrap_ci(g[\"ESR_iGuide_organ_flags\"][good],\n",
    "                                                   g[pred][good], mfunc)\n",
    "                        recs.append(dict(group=grp, model=nice, metric=mname,\n",
    "                                         modality=mod.upper(), est=est, lo=lo, hi=hi))\n",
    "            # permutation p-value (CT vs CTA) once per group\n",
    "            for grp in groups:\n",
    "                g1=df[(df[group_var]==grp)&(df[\"test_type\"]==\"ct\")]\n",
    "                g2=df[(df[group_var]==grp)&(df[\"test_type\"]==\"angiography\")]\n",
    "                good1, good2 = mask(g1[\"ESR_iGuide_organ_flags\"],g1[pred]), mask(g2[\"ESR_iGuide_organ_flags\"],g2[pred])\n",
    "                gap=METRICS[mname](g2[\"ESR_iGuide_organ_flags\"][good2],g2[pred][good2]) - \\\n",
    "                    METRICS[mname](g1[\"ESR_iGuide_organ_flags\"][good1],g1[pred][good1])\n",
    "                pool_y=np.concatenate([g1[\"ESR_iGuide_organ_flags\"][good1], g2[\"ESR_iGuide_organ_flags\"][good2]])\n",
    "                pool_p=np.concatenate([g1[pred][good1], g2[pred][good2]])\n",
    "                hits=0\n",
    "                for _ in range(N_PERM):\n",
    "                    idx=RNG.permutation(len(pool_y))\n",
    "                    perm_gap=METRICS[mname](pool_y[idx[len(g1[good1]):]],pool_p[idx[len(g1[good1]):]]) - \\\n",
    "                             METRICS[mname](pool_y[idx[:len(g1[good1])]],pool_p[idx[:len(g1[good1])]])\n",
    "                    hits += abs(perm_gap)>=abs(gap)\n",
    "                p=(hits+1)/(N_PERM+1)\n",
    "                recs.append(dict(group=grp, model=nice, metric=mname,\n",
    "                                 modality=\"p\", est=p))\n",
    "    tidy=pd.DataFrame(recs)\n",
    "    return tidy\n",
    "\n",
    "age_tbl = build_table(\"age_bin\", [\"<65\",\"≥65\"])\n",
    "sex_tbl = build_table(\"Patient Sex\", [\"Female\",\"Male\"])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "#  Cleveland-dot plot function\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "#  6-BIS. Cleveland-dot plot with custom colours\n",
    "# -------------------------------------------------------------\n",
    "MODEL_COLORS = {           # <-- customise here if you like\n",
    "    \"Clinicians\": \"#404040\",   # dark grey\n",
    "    \"GPT-4\"     : \"#1b7837\",   # green\n",
    "    \"Claude\"    : \"#762a83\"    # purple\n",
    "}\n",
    "BASE_COLOR = \"#d7191c\"     # red   (baseline subgroup)\n",
    "COMP_COLOR = \"#2c7bb6\"     # blue  (comparison subgroup)\n",
    "\n",
    "def cleveland(tidy, groups, fname, title,\n",
    "              base_label=None, comp_label=None,\n",
    "              use_mod=\"CT\"):\n",
    "    \"\"\"\n",
    "    y-axis = metrics; x-axis = rate (%).\n",
    "    For each metric we draw three model clusters, each with two dots\n",
    "    (baseline → red, comparison → blue) connected by a line whose\n",
    "    colour identifies the model.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 4))\n",
    "    row_spacing = len(MODELS) + 1\n",
    "    y_base = np.arange(len(METRICS)) * row_spacing\n",
    "\n",
    "    for col_idx, (raw, mdl) in enumerate(MODELS.items()):\n",
    "        y_offsets = y_base + col_idx\n",
    "        for k, metric in enumerate(METRICS):\n",
    "            y_start = y_base[k] - 0.5             # y_base: first row index for this metric\n",
    "            y_end   = y_start + row_spacing       # row_spacing = len(MODELS) + 1\n",
    "            ax.axhspan(y_start, y_end,\n",
    "               color=row_colors[k],\n",
    "               alpha=0.15,                # subtle; bump to 0.25 if needed\n",
    "               zorder=0)\n",
    "            # ----- baseline dot (groups[0]) -----\n",
    "            base_val = tidy.query(\n",
    "                \"metric==@metric & model==@mdl & group==@groups[0] & modality==@use_mod\"\n",
    "            ).est.values[0]\n",
    "            ax.scatter(base_val, y_offsets[k],\n",
    "                       s=50, color=BASE_COLOR, zorder=3)\n",
    "\n",
    "            # ----- comparison dot (groups[1]) -----\n",
    "            comp_val = tidy.query(\n",
    "                \"metric==@metric & model==@mdl & group==@groups[1] & modality==@use_mod\"\n",
    "            ).est.values[0]\n",
    "            ax.scatter(comp_val, y_offsets[k],\n",
    "                       s=50, color=COMP_COLOR, zorder=3)\n",
    "\n",
    "            # ----- connector line coloured by model -----\n",
    "            ax.hlines(y_offsets[k],\n",
    "                      xmin=min(base_val, comp_val),\n",
    "                      xmax=max(base_val, comp_val),\n",
    "                      color=MODEL_COLORS[mdl],\n",
    "                      lw=2, zorder=1)\n",
    "            #ax.grid(axis=\"y\", color=\"#eeeeee\", linewidth=1, zorder=0)   # light grey\n",
    "            #ax.set_axisbelow(True)\n",
    "            # ----- significance star next to comparison dot -----\n",
    "            p_val = tidy.query(\n",
    "                \"metric==@metric & model==@mdl & group==@groups[1] & modality=='p'\"\n",
    "            ).est.values[0]\n",
    "            if p_val < 0.05:\n",
    "                star = \"***\" if p_val < .001 else (\"**\" if p_val < .01 else \"*\")\n",
    "                mid_x = (base_val + comp_val) / 2\n",
    "                ax.text(mid_x, y_offsets[k], star,\n",
    "                        va=\"center\", fontsize=11, color=\"black\")\n",
    "\n",
    "    # aesthetics -------------------------------------------------\n",
    "    ax.set_yticks(y_base + (len(MODELS)-1)/2)\n",
    "    ax.set_yticklabels([m.capitalize() for m in METRICS])\n",
    "    ax.set_xlim(60, 100)\n",
    "    ax.set_xlabel(\"Rate (%)\")\n",
    "    ax.set_title(title, loc=\"left\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.grid(axis='x', alpha=.2)\n",
    "\n",
    "    # legends\n",
    "    from matplotlib.lines import Line2D\n",
    "    model_legend = [Line2D([0], [0], color=col, lw=3, label=mdl)\n",
    "                    for mdl, col in MODEL_COLORS.items()]\n",
    "    dot_legend   = [Line2D([0], [0], marker='o', color='w',\n",
    "                           markerfacecolor=BASE_COLOR, markersize=8,\n",
    "                           label=base_label or groups[0]),\n",
    "                    Line2D([0], [0], marker='o', color='w',\n",
    "                           markerfacecolor=COMP_COLOR, markersize=8,\n",
    "                           label=comp_label or groups[1])]\n",
    "    leg1 = ax.legend(handles=model_legend, title=\"Model\", loc=\"lower right\",\n",
    "                     frameon=False)\n",
    "    ax.add_artist(leg1)\n",
    "    ax.legend(handles=dot_legend, title=\"Sub-group\", loc=\"upper right\",\n",
    "              frameon=True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT_DIR / fname, dpi=600)\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# 7-bis.  Render the Cleveland plots with colours\n",
    "# -------------------------------------------------------------\n",
    "cleveland(age_tbl,\n",
    "          [\"<65\", \"≥65\"],\n",
    "          \"Figure3A_CT_age_cleveland.png\",\n",
    "          \"A\",\n",
    "          base_label=\"< 65\", comp_label=\"≥ 65\",\n",
    "          use_mod=\"CT\") \n",
    "cleveland(sex_tbl,\n",
    "          [\"Male\", \"Female\"],\n",
    "          \"Figure2A_CT_sex_cleveland.png\",\n",
    "          \"A\",\n",
    "          base_label=\"Male\", comp_label=\"Female\",\n",
    "          use_mod=\"CT\")\n",
    "cleveland(age_tbl,\n",
    "          [\"<65\", \"≥65\"],\n",
    "          \"Figure3B_CTA_age_cleveland.png\",\n",
    "          \"B\",\n",
    "          base_label=\"< 65\", comp_label=\"≥ 65\",\n",
    "          use_mod=\"ANGIOGRAPHY\")\n",
    "\n",
    "cleveland(sex_tbl,\n",
    "          [\"Male\", \"Female\"],\n",
    "          \"Figure2B_CTA_sex_cleveland.png\",\n",
    "          \"B\",\n",
    "          base_label=\"Male\", comp_label=\"Female\",\n",
    "          use_mod=\"ANGIOGRAPHY\")\n",
    "\n",
    "\n",
    "print(\"✓ colour-coded Cleveland plots saved to\", OUT_DIR)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
